{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ca3b91",
   "metadata": {},
   "source": [
    "Mini-projet XAI ‚Äî **ProtoPNet (Prototypical Part Network)**\n",
    "\"This Looks Like That: Deep Learning for Interpretable Image Recognition\"\n",
    "\n",
    "**√âtudiant**: CHAIBOU SAIDOU Abdoulaye<br>\n",
    "**Professeur**: Tawfik Masrour<br>\n",
    "**Date**: 16 D√©cembre 2025<br>\n",
    "**Fili√®re**: IATD-SI<br>\n",
    "**Etablissement**: [ENSAM-Mekn√®s](https://ensam.umi.ac.ma)\n",
    "\n",
    "**Remerciements**:\n",
    "Ce projet est bas√© sur l'article \"This Looks Like That: Deep Learning for \n",
    "Interpretable Image Recognition\" (NeurIPS 2019), par Chaofan Chen*, Oscar Li*, \n",
    "Chaofan Tao, Alina Jade Barnett, Jonathan Su, et Cynthia Rudin (Duke University).\n",
    "Code original: [PPNet repo](https://github.com/cfchen-duke/ProtoPNet).\n",
    "\n",
    "**Infos**: Ce notebook pr√©sente bri√®vement la technique interpr√©table d'explication des r√©seaux de convolutifs appel√©e Prototypical Part Network par ses auteurs officiels, sous forme de mini-projet (IA Explicable) de classe. Nous utilisons egalement un mod√®le pr√©-entra√Æn√© par *Alina Jade Barnett* pour l'analyse de la methode, par soucis de simplicit√© et de gain de temps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c58ab",
   "metadata": {},
   "source": [
    "- [Introduction](#introduction)\n",
    "- [Explication globale de la methode](#explication)\n",
    "- [Exemple](#exemple)\n",
    "- [R√©f√©rences](#r√©f√©rences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd82b4f",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "**LE PROBL√àME DES BO√éTES NOIRES** :\n",
    "\n",
    "Les r√©seaux de neurones profonds (CNN) sont extr√™mement performants pour la\n",
    "classification d'images, MAIS ils sont des \"bo√Ætes noires\" inexplicables :\n",
    "\n",
    "  M√©decin : \"Pourquoi le mod√®le dit que c'est un cancer ?\"\n",
    "  CNN Classique : \"ü§∑ R√©sultat = 95% cancer\"\n",
    "  \n",
    "  Juge : \"Sur quelle base le mod√®le a identifi√© cette personne ?\"\n",
    "  CNN Classique : \"ü§∑ Confiance = 98%\"\n",
    "\n",
    "‚ùå Cons√©quences :\n",
    "  - Impossible de v√©rifier le raisonnement\n",
    "  - Risque de biais cach√©s\n",
    "  - Manque de confiance des experts\n",
    "  - Non-conforme aux r√©gulations (RGPD, FDA)\n",
    "\n",
    "üí° LA SOLUTION PROTOPNET :\n",
    "\n",
    "Au lieu d'une bo√Æte noire, ProtoPNet fonctionne comme l'esprit humain :\n",
    "raisonnement par SIMILITUDE avec des CAS M√âMORIS√âS (prototypes).\n",
    "\n",
    "  M√©decin : \"Pourquoi cancer ?\"\n",
    "  ProtoPNet : \"Cette r√©gion ressemble √† 85% √† ce prototype de m√©lanome,\n",
    "               cette autre r√©gion ressemble √† 78% √† cet autre prototype...\"\n",
    "  M√©decin : ‚úÖ \"Je peux v√©rifier ! Le raisonnement est correct.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c277e9a",
   "metadata": {},
   "source": [
    "## Explication globale de la methode\n",
    "### Type d'explication\n",
    "\n",
    "üìä GLOBALE + LOCALE :\n",
    "  - GLOBALE : Les prototypes sont appris une fois pour toutes les classes\n",
    "  - LOCALE : Chaque pr√©diction s'explique par similarit√© aux prototypes\n",
    "\n",
    "üñºÔ∏è DOMAINE D'APPLICATION : IMAGES / CNN\n",
    "  - Classification d'oiseaux (dataset CUB-200)\n",
    "  - Diagnostic m√©dical (dermatologie, radiologie)\n",
    "  - Contr√¥le qualit√© industriel\n",
    "  - Toute t√¢che de classification fine-grained\n",
    "\n",
    "üéØ AVANTAGE CL√â : INTERPR√âTABILIT√â INTRINS√àQUE\n",
    "\n",
    "Contrairement √† LIME, SHAP, Grad-CAM (m√©thodes POST-HOC qui approximent),\n",
    "ProtoPNet est INTRINS√àQUEMENT INTERPR√âTABLE :\n",
    "  - L'explication fait partie de l'architecture\n",
    "  - Pas d'approximation\n",
    "  - Fid√©lit√© garantie √† 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f7ed83",
   "metadata": {},
   "source": [
    "### ANALOGIE HUMAINE\n",
    "\n",
    "Imaginez que vous apprenez √† reconna√Ætre des oiseaux :\n",
    "\n",
    "1Ô∏è‚É£ PHASE D'APPRENTISSAGE (m√©morisation de prototypes) :\n",
    "   \n",
    "   Vous voyez beaucoup d'oiseaux et m√©morisez des CARACT√âRISTIQUES TYPIQUES :\n",
    "   ```\n",
    "   üê¶ Cardinals :\n",
    "      ‚Üí Prototype A : \"cr√™te rouge vif caract√©ristique\"\n",
    "      ‚Üí Prototype B : \"bec orange pointu\"\n",
    "      ‚Üí Prototype C : \"masque noir autour des yeux\"\n",
    "   \n",
    "   üê¶ Geais bleus :\n",
    "      ‚Üí Prototype D : \"plumes bleues brillantes\"\n",
    "      ‚Üí Prototype E : \"bande noire sur la t√™te\"\n",
    "      ‚Üí Prototype F : \"bout des ailes blanc\"\n",
    "```\n",
    "2Ô∏è‚É£ PHASE DE RECONNAISSANCE (nouvelle image) :\n",
    "   \n",
    "   Vous voyez un nouvel oiseau inconnu :\n",
    "   \n",
    "   \n",
    "   | üê¶ Oiseau myst√®re |\n",
    "|------------------|\n",
    "| ‚úì Cette partie ressemble beaucoup au **Prototype A** |\n",
    "| ‚úì Cette autre partie ressemble au **Prototype B** |\n",
    "| ‚úó Pas de similarit√© avec les prototypes de **geai bleu** |\n",
    "\n",
    "   \n",
    "   CONCLUSION : \"C'est probablement un cardinal !\"\n",
    "\n",
    "3Ô∏è‚É£ EXPLICATION :\n",
    "   \n",
    "   Si on vous demande \"Pourquoi cardinal ?\" :\n",
    "   ```\n",
    "   ‚Üí \"Parce que sa cr√™te ressemble au Prototype A (85% similaire)\"\n",
    "   ‚Üí \"Et son bec ressemble au Prototype B (78% similaire)\"\n",
    "   ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b096fc9",
   "metadata": {},
   "source": [
    "### C'EST EXACTEMENT CE QUE FAIT PROTOPNET !\n",
    "\n",
    "üèóÔ∏è ARCHITECTURE EN 3 √âTAPES :\n",
    "```\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ  Image Input    ‚îÇ  üì∏ Exemple : photo d'oiseau 224√ó224√ó3\n",
    "   ‚îÇ  (224√ó224√ó3)    ‚îÇ\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ  CNN Backbone   ‚îÇ  üîß VGG16 / ResNet : extraction de features\n",
    "   ‚îÇ  (ex: VGG16)    ‚îÇ     Sortie : feature map H√óW√óD\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     (ex: 14√ó14√ó128)\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇ Prototype Layer ‚îÇ  üéØ Compare chaque r√©gion aux m prototypes\n",
    "   ‚îÇ  (m prototypes) ‚îÇ     Calcule similarit√©s spatiales\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     Sortie : m scores de similarit√©\n",
    "            ‚îÇ\n",
    "            ‚ñº\n",
    "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "   ‚îÇClassification   ‚îÇ  üìä Combine les similarit√©s avec poids appris\n",
    "   ‚îÇ     Layer       ‚îÇ     Sortie : scores par classe\n",
    "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "![diagram of the architecture](images/architectureppnet.png)\n",
    "üì§ QUE PRODUIT LA M√âTHODE ?\n",
    "\n",
    "Pour chaque image √† classifier :\n",
    "\n",
    "1. HEATMAP DE SIMILARIT√â:\n",
    "```\n",
    " pour chaque prototype activ√© ‚Üí Montre QUELLE R√âGION de l'image ressemble au prototype\n",
    " ```\n",
    "\n",
    "2. TOP-K PROTOTYPES:\n",
    "```\n",
    "les plus similaires ‚Üí \"Les 5 prototypes qui matchent le mieux avec cette image\"\n",
    "```\n",
    "3. EXPLICATION VISUELLE :\n",
    "   ‚Üí \"Cette partie [bbox rouge] ressemble √† 85% au Prototype #42\"\n",
    "   ‚Üí \"Prototype #42 = cr√™te rouge d'un cardinal\"\n",
    "\n",
    "4. RAISONNEMENT COMPLET :\n",
    "```\n",
    "   ‚Üí Similarit√© prototype 1 : 0.85  √ó  Poids 1.2  =  +1.02\n",
    "   ‚Üí Similarit√© prototype 2 : 0.78  √ó  Poids 0.9  =  +0.70\n",
    "   ‚Üí Similarit√© prototype 3 : 0.12  √ó  Poids -0.3 =  -0.04\n",
    "   ‚Üí ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "   ‚Üí TOTAL score pour \"Cardinal\" : 1.68 ‚Üí Softmax ‚Üí 92%\n",
    "```\n",
    "üéØ FAMILLE XAI :\n",
    "Comparaison entre ProtoPNet (interpr√©tabilit√© intrins√®que) et les m√©thodes post-hoc courantes (LIME, SHAP, Grad-CAM) :\n",
    "\n",
    "| Aspect | ProtoPNet (interpr√©tabilit√© intrins√®que) | M√©thodes post-hoc (LIME, SHAP, Grad-CAM) |\n",
    "|------|------------------------------------------|------------------------------------------|\n",
    "| Moment de l‚Äôexplication | **Pendant la pr√©diction** | Apr√®s la pr√©diction |\n",
    "| Principe | Raisonnement par **similarit√© avec des prototypes** | Approximation ou analyse a posteriori |\n",
    "| Lien avec le mod√®le | L‚Äôexplication **fait partie du mod√®le** | L‚Äôexplication est **ajout√©e par-dessus** |\n",
    "| Fid√©lit√© √† la d√©cision | **100 % fid√®le** (pas d‚Äôapproximation) | Approximative |\n",
    "| Type d‚Äôexplication | ¬´ *Cette partie ressemble √† ce prototype* ¬ª | Importance de pixels / features |\n",
    "| Raisonnement | **Case-Based Reasoning** (par cas) | Attribution de contribution |\n",
    "| Stabilit√© | Stable (m√™mes prototypes) | Peut varier selon les param√®tres |\n",
    "| Co√ªt de calcul | Mod√©r√© | SHAP souvent **tr√®s co√ªteux** |\n",
    "| Compr√©hensible par humain | **Oui (visuel + s√©mantique)** | Parfois difficile √† interpr√©ter |\n",
    "| Confiance utilisateur | √âlev√©e | Variable |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0d064",
   "metadata": {},
   "source": [
    "### NOTATIONS\n",
    "\n",
    "- $x ‚àà ‚Ñù^{224\\times224\\times3}$     : image d'entr√©e RGB\n",
    "- $f(x) ‚àà ‚Ñù^{H\\times\\text{W}\\times\\text{D}}$       : carte de features extraite par le CNN\n",
    "                          (ex: H=14, W=14, D=128 pour input $224\\times224$)\n",
    "- $P = {p‚ÇÅ, ..., p‚Çò}$     : ensemble des m prototypes\n",
    "                          (chaque $p_j ‚àà ‚Ñù^D$, m√™me dimension que features)\n",
    "- $d(¬∑,¬∑)$                : distance L2 (euclidienne)\n",
    "- $K$                     : nombre de classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d08aa",
   "metadata": {},
   "source": [
    "### √âQUATION ‚Äî SIMILARIT√â ENTRE UNE IMAGE ET UN PROTOTYPE (ProtoPNet)\n",
    "\n",
    "Soit une image d‚Äôentr√©e $x \\in \\mathbb{R}^{224 \\times 224 \\times 3}$.\n",
    "Les couches convolutionnelles du r√©seau extraient une repr√©sentation latente :\n",
    "\n",
    "$$\n",
    "f(x) \\in \\mathbb{R}^{H \\times W \\times D}\n",
    "$$\n",
    "\n",
    "Dans le cas du dataset CUB-200-2011 :\n",
    "$$\n",
    "H = W = 7, \\quad D \\in \\{128, 256, 512\\}\n",
    "$$\n",
    "\n",
    "Le r√©seau apprend un ensemble de $m$ prototypes :\n",
    "$$\n",
    "P = \\{p_j\\}_{j=1}^{m}, \\quad\n",
    "p_j \\in \\mathbb{R}^{H_1 \\times W_1 \\times D}\n",
    "$$\n",
    "\n",
    "Dans les exp√©riences ProtoPNet :\n",
    "$$\n",
    "H_1 = W_1 = 1\n",
    "$$\n",
    "\n",
    "Chaque prototype $p_j$ repr√©sente donc un **motif latent local**, correspondant √† une **partie prototypique de l‚Äôobjet** dans l‚Äôimage (ex. : t√™te d‚Äôoiseau, aile, plumage).\n",
    "\n",
    "---\n",
    "\n",
    "#### Calcul de la similarit√© √† un prototype\n",
    "\n",
    "Pour un prototype donn√© $p_j$, on calcule sa similarit√© avec toutes les r√©gions spatiales de la carte de caract√©ristiques $f(x)$.\n",
    "\n",
    "#### 1. Distance L2 au carr√©\n",
    "\n",
    "Pour chaque position spatiale $(h,w)$ :\n",
    "\n",
    "$$\n",
    "d^2\\!\\left(f(x)_{h,w},\\, p_j\\right)\n",
    "=\n",
    "\\left\\| f(x)_{h,w} - p_j \\right\\|_2^2\n",
    "=\n",
    "\\sum_{k=1}^{D}\n",
    "\\left( f(x)_{h,w,k} - p_j[k] \\right)^2\n",
    "$$\n",
    "\n",
    "o√π :\n",
    "- $f(x)_{h,w} \\in \\mathbb{R}^D$ est le vecteur de caract√©ristiques local,\n",
    "- $p_j \\in \\mathbb{R}^D$ est le prototype.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Conversion distance ‚Üí similarit√©\n",
    "\n",
    "La distance est transform√©e en score de similarit√© par une fonction exponentielle d√©croissante :\n",
    "\n",
    "$$\n",
    "g_{p_j}(z)\n",
    "=\n",
    "\\max_{\\tilde{z} \\in \\mathrm{patches}(z)}\n",
    "\\;\n",
    "\\log\\!\\left(\n",
    "\\frac{\n",
    "\\|\\tilde{z} - p_j\\|_2^2 + 1\n",
    "}{\n",
    "\\|\\tilde{z} - p_j\\|_2^2 + \\varepsilon\n",
    "}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\textbf{avec :}\n",
    "$$\n",
    "$$\n",
    "z = f(x)\n",
    "\\quad \\text{: sortie des couches convolutionnelles}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{z}\n",
    "\\quad \\text{: patch latent de } z \\text{ de m√™me dimension que le prototype } p_j\n",
    "$$\n",
    "\n",
    "$$\n",
    "d^2 = \\|\\tilde{z} - p_j\\|_2^2\n",
    "\\quad \\text{: distance euclidienne au carr√© (L2)}\n",
    "$$\n",
    "\n",
    "Cette fonction garantit que :\n",
    "- Quand $d^2 \\to 0$ :\n",
    "$$\n",
    "g_{p_j}(z) \\;\\longrightarrow\\; \\log\\left(\\frac{1}{\\varepsilon}\\right)\n",
    "\\quad \\text{(grande similarit√©)}\n",
    "$$\n",
    "- Quand $d^2 \\to \\infty$ :\n",
    "$$\n",
    "g_{p_j}(z) \\;\\longrightarrow\\; \\log(1) = 0\n",
    "\\quad \\text{(aucune similarit√©)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Agr√©gation spatiale (Global Max Pooling)\n",
    "\n",
    "Le score de similarit√© final entre l‚Äôimage $x$ et le prototype $p_j$ est obtenu par :\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\mathrm{sim}(x, p_j)\n",
    "=\n",
    "\\max_{h,w}\n",
    "\\;\n",
    "\\exp\\!\\left(\n",
    "- d^2\\!\\left(f(x)_{h,w}, p_j\\right)\n",
    "\\right)\n",
    "}\n",
    "$$\n",
    "\n",
    "Cette op√©ration s√©lectionne la **r√©gion de l‚Äôimage la plus proche du prototype** dans l‚Äôespace latent.\n",
    "\n",
    "---\n",
    "\n",
    "#### Intuition\n",
    "\n",
    "$$\n",
    "\\text{``Quelle est la r√©gion de l‚Äôimage qui ressemble le plus au prototype } p_j \\text{ ?''}\n",
    "$$\n",
    "\n",
    "- Si $\\mathrm{sim}(x, p_j)$ est √©lev√© :\n",
    "  - il existe une r√©gion de l‚Äôimage tr√®s proche du prototype,\n",
    "  - le concept repr√©sent√© par $p_j$ est fortement pr√©sent.\n",
    "- Sinon :\n",
    "  - le prototype n‚Äôest pas pertinent pour cette image.\n",
    "\n",
    "---\n",
    "\n",
    "#### R√¥le dans la pr√©diction finale\n",
    "\n",
    "Chaque classe $k \\in \\{1,\\dots,K\\}$ est associ√©e √† un sous-ensemble de prototypes $P_k \\subseteq P$.\n",
    "Les scores de similarit√© produits par tous les prototypes sont ensuite combin√©s par une couche lin√©aire :\n",
    "\n",
    "$$\n",
    "\\text{logits}(x) = W_h \\cdot\n",
    "\\begin{bmatrix}\n",
    "\\mathrm{sim}(x,p_1) \\\\\n",
    "\\vdots \\\\\n",
    "\\mathrm{sim}(x,p_m)\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "puis normalis√©s par une fonction softmax pour produire les probabilit√©s de classification.\n",
    "\n",
    "---\n",
    "\n",
    "**ProtoPNet peut ainsi √™tre interpr√©t√© comme un mod√®le prenant ses d√©cisions en comparant explicitement l‚Äôimage √† des prototypes visuels interpr√©tables.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e0a991",
   "metadata": {},
   "source": [
    "##### Exemple concret\n",
    "\n",
    "###### Classe **\"Cardinal\"** ($ k = 5 $)\n",
    "\n",
    "- **Prototype 25** (cr√™te rouge)  \n",
    "  $$ \\mathrm{sim} = 0.85, \\quad w_{5,25} = 1.2 \\quad \\Rightarrow \\quad +1.02 $$\n",
    "\n",
    "- **Prototype 26** (bec orange)  \n",
    "  $$ \\mathrm{sim} = 0.78, \\quad w_{5,26} = 0.9 \\quad \\Rightarrow \\quad +0.70 $$\n",
    "\n",
    "- **Prototype 27** (masque noir)  \n",
    "  $$ \\mathrm{sim} = 0.65, \\quad w_{5,27} = 0.7 \\quad \\Rightarrow \\quad +0.46 $$\n",
    "\n",
    "- **Autres 97 prototypes**  \n",
    "  contribution faible  \n",
    "  $$ \\Rightarrow +0.32 $$\n",
    "\n",
    "---\n",
    "\n",
    "###### Score total\n",
    "\n",
    "$$\n",
    "g_5(x) = 2.50\n",
    "\\quad \\Rightarrow \\quad\n",
    "P(\\text{Cardinal} \\mid x) = 0.92\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c403de2",
   "metadata": {},
   "source": [
    "### Algorithme d'entra√Ænement de ProtoPNet\n",
    "\n",
    "L'entra√Ænement de **ProtoPNet** est structur√© en **trois √©tapes principales**, pouvant √™tre r√©p√©t√©es plusieurs fois :\n",
    "\n",
    "1. **Optimisation par descente de gradient stochastique (SGD)** des couches convolutionnelles et des prototypes  \n",
    "2. **Projection des prototypes** sur des patches latents r√©els  \n",
    "3. **Optimisation convexe de la derni√®re couche fully-connected**\n",
    "\n",
    "L'objectif global est d'apprendre un **espace latent interpr√©table**, o√π chaque prototype repr√©sente un concept visuel discriminant pour une classe donn√©e.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb0b79",
   "metadata": {},
   "source": [
    "#### √âtape 1 ‚Äî Apprentissage de l‚Äôespace latent (SGD)\n",
    "\n",
    "Dans cette premi√®re phase, on apprend :\n",
    "- les param√®tres des couches convolutionnelles $w_conv$\n",
    "- les prototypes $P = {p_j}$\n",
    "\n",
    "La derni√®re couche de classification $h$ est **fig√©e** afin d'imposer une structure s√©mantique dans l‚Äôespace latent.\n",
    "\n",
    "$$\n",
    "\\min_{P, w_{\\text{conv}}}\n",
    "\\frac{1}{n} \\sum_{i=1}^{n}\n",
    "\\text{CrsEnt}(h \\circ g_p \\circ f(x_i), y_i)\n",
    "+ \\lambda_1 \\, \\text{Clst}\n",
    "+ \\lambda_2 \\, \\text{Sep}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d2f455",
   "metadata": {},
   "source": [
    "La fonction de perte est compos√©e de trois termes :\n",
    "\n",
    "- **Cross-Entropy** : p√©nalise les erreurs de classification\n",
    "- **Co√ªt de clustering (Clst)** : rapproche les patches latents d‚Äôune image vers les prototypes de sa classe\n",
    "- **Co√ªt de s√©paration (Sep)** : √©loigne les patches latents des prototypes des autres classes\n",
    "\n",
    "$$\n",
    "\\text{Clst} =\n",
    "\\frac{1}{n} \\sum_{i=1}^{n}\n",
    "\\min_{j : p_j \\in P_{y_i}}\n",
    "\\min_{z \\in \\text{patches}(f(x_i))}\n",
    "\\| z - p_j \\|_2^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{Sep} =\n",
    "-\\frac{1}{n} \\sum_{i=1}^{n}\n",
    "\\min_{j : p_j \\notin P_{y_i}}\n",
    "\\min_{z \\in \\text{patches}(f(x_i))}\n",
    "\\| z - p_j \\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377ee79",
   "metadata": {},
   "source": [
    "#### R√¥le du co√ªt de s√©paration\n",
    "\n",
    "Le terme **Sep**, introduit dans ProtoPNet, emp√™che un prototype d'une classe donn√©e\n",
    "de repr√©senter un concept visuel pr√©sent dans d'autres classes.\n",
    "\n",
    "Cela am√©liore la **discrimination inter-classes** et renforce l‚Äôinterpr√©tabilit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15243c17",
   "metadata": {},
   "source": [
    "#### Fixation de la derni√®re couche pendant le SGD\n",
    "\n",
    "La matrice de poids $w_h$ de la couche finale est fix√©e comme suit :\n",
    "\n",
    "- Connexion **positive** entre un prototype et sa classe\n",
    "- Connexion **n√©gative** avec les autres classes\n",
    "\n",
    "Cela force le r√©seau √† apprendre des prototypes r√©ellement sp√©cifiques √† leur classe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac112fa5",
   "metadata": {},
   "source": [
    "$$\n",
    "w_h^{(k,j)} =\n",
    "\\begin{cases}\n",
    "1 & \\text{si } p_j \\in P_k \\\\\n",
    "-0.5 & \\text{sinon}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8efd958",
   "metadata": {},
   "source": [
    "#### √âtape 2 ‚Äî Projection des prototypes\n",
    "\n",
    "Apr√®s l‚Äôapprentissage, chaque prototype est projet√© sur le **patch latent r√©el**\n",
    "le plus proche appartenant √† sa classe.\n",
    "\n",
    "Cela permet d‚Äôassocier chaque prototype √† une **r√©gion visuelle concr√®te** d‚Äôune image d‚Äôentra√Ænement.\n",
    "\n",
    "$$\n",
    "p_j \\leftarrow\n",
    "\\arg\\min_{z \\in Z_j}\n",
    "\\| z - p_j \\|_2^2\n",
    "\\quad\n",
    "\\text{avec }\n",
    "Z_j = \\{ z \\in \\text{patches}(f(x_i)) \\mid y_i = k \\}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2a0fc7",
   "metadata": {},
   "source": [
    "#### Interpr√©tation\n",
    "\n",
    "Apr√®s projection :\n",
    "- chaque prototype correspond √† **un patch d‚Äôimage r√©el**\n",
    "- la visualisation devient directe et humaine\n",
    "- l‚Äôinterpr√©tabilit√© du mod√®le est maximale\n",
    "\n",
    "$$\n",
    "\\Delta_{\\max} = m \\log\\big((1+\\delta)(2-\\delta)\\big)\n",
    "$$\n",
    "$$\n",
    "\\text{Si } \n",
    "\\text{logit}_{\\text{top1}} - \\text{logit}_{\\text{top2}}\n",
    "\\ge 2 \\Delta_{\\max}\n",
    "\\Rightarrow \\text{classe inchang√©e}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2405a257",
   "metadata": {},
   "source": [
    "#### √âtape 3 ‚Äî Optimisation convexe de la derni√®re couche\n",
    "\n",
    "Dans cette derni√®re phase :\n",
    "- les couches convolutionnelles et prototypes sont fig√©es\n",
    "- seuls les poids $w_h$ sont optimis√©s\n",
    "\n",
    "L‚Äôobjectif est de **r√©duire les connexions n√©gatives inutiles**.\n",
    "\n",
    "$$\n",
    "\\min_{w_h}\n",
    "\\frac{1}{n} \\sum_{i=1}^{n}\n",
    "\\text{CrsEnt}(h \\circ g_p \\circ f(x_i), y_i)\n",
    "+ \\lambda \\sum_{k=1}^{K}\n",
    "\\sum_{j : p_j \\notin P_k}\n",
    "| w_h^{(k,j)} |\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d31b0f",
   "metadata": {},
   "source": [
    "#### Intuition finale\n",
    "\n",
    "Cette √©tape :\n",
    "- am√©liore la pr√©cision\n",
    "- favorise un raisonnement **positif** (\"cette image ressemble √†‚Ä¶\")\n",
    "- √©vite le raisonnement n√©gatif (\"ce n‚Äôest pas cette classe\")\n",
    "\n",
    "L‚Äôespace latent et les prototypes restent inchang√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d45db23",
   "metadata": {},
   "source": [
    "### Projection des prototypes\n",
    "\n",
    "Afin de rendre les prototypes **visuellement interpr√©tables**, chaque prototype est projet√©\n",
    "(¬´ push ¬ª) vers un **patch latent r√©el** provenant des images d‚Äôentra√Ænement de **la m√™me classe**.\n",
    "\n",
    "Apr√®s projection, chaque prototype peut √™tre assimil√© √† un **patch d‚Äôimage concret**, ce qui\n",
    "permet une visualisation directe et une interpr√©tation humaine du raisonnement du r√©seau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5445bef0",
   "metadata": {},
   "source": [
    "#### Principe\n",
    "\n",
    "- Les prototypes sont appris dans l‚Äôespace latent\n",
    "- Ils ne correspondent pas n√©cessairement √† des patches r√©els\n",
    "- La projection remplace chaque prototype par le patch latent r√©el **le plus proche**\n",
    "- La classe du patch projet√© est **identique** √† celle du prototype\n",
    "$$\n",
    "p_j \\leftarrow\n",
    "\\arg\\min_{z \\in Z_j}\n",
    "\\| z - p_j \\|_2^2\n",
    "$$\n",
    "$$\n",
    "Z_j =\n",
    "\\left\\{\n",
    "\\tilde{z} \\;\\middle|\\;\n",
    "\\tilde{z} \\in \\text{patches}(f(x_i)),\n",
    "\\; \\forall i \\text{ tel que } y_i = k\n",
    "\\right\\}\n",
    "$$\n",
    "o√π :\n",
    "- $p_j$ est un prototype appartenant √† la classe $k$ (i.e. $p_j ‚àà P_k$)\n",
    "- $f(x_i)$ d√©signe la repr√©sentation latente de l‚Äôimage $x_i$\n",
    "- $\\text{patches}(f(x_i))$ est l‚Äôensemble des patches latents extraits\n",
    "- $Z_j$ contient tous les patches latents des images d‚Äôentra√Ænement de la classe $k$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0e08db",
   "metadata": {},
   "source": [
    "#### Intuition g√©om√©trique\n",
    "\n",
    "La projection correspond √† un **d√©placement minimal** du prototype dans l‚Äôespace latent,\n",
    "vers un point r√©el du jeu d‚Äôentra√Ænement.\n",
    "\n",
    "Ainsi :\n",
    "- la structure de l‚Äôespace latent est conserv√©e\n",
    "- les prototypes deviennent interpr√©tables\n",
    "- la classification reste stable si le d√©placement est faible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b619f",
   "metadata": {},
   "source": [
    "#### Impact sur la classification\n",
    "\n",
    "La projection pourrait, en th√©orie, modifier les distances entre prototypes et patches latents,\n",
    "et donc affecter les logits de classification.\n",
    "\n",
    "Le th√©or√®me suivant formalise les conditions sous lesquelles la projection **ne modifie pas**\n",
    "la pr√©diction du mod√®le."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5234939c",
   "metadata": {},
   "source": [
    "#### Notation pour l‚Äôanalyse th√©orique\n",
    "\n",
    "Pour l‚Äôanalyse, on adopte une notation alternative :\n",
    "\n",
    "- $p_l^k$ : le $l-i√®me$ prototype de la classe $k$\n",
    "- $b_l^k$ : valeur du prototype **avant projection**\n",
    "- $a_l^k$ : valeur du prototype **apr√®s projection**\n",
    "\n",
    "On consid√®re une image d‚Äôentr√©e $x$, correctement classifi√©e avant projection,\n",
    "et on note :\n",
    "\n",
    "- $z_l^k$ : le patch latent de $f(x)$ le plus proche du prototype $p_l^k$\n",
    "- $c$ : la classe correcte de l‚Äôimage $x$\n",
    "\n",
    "Le th√©or√®me √©tablit que, sous certaines hypoth√®ses de **d√©placement limit√©**\n",
    "des prototypes et de **marge suffisante entre les logits**, la projection\n",
    "des prototypes n‚Äôalt√®re pas la pr√©diction finale du r√©seau."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9331e75",
   "metadata": {},
   "source": [
    "### Visualisation des prototypes\n",
    "\n",
    "Apr√®s la projection, chaque prototype $p_j$ correspond √† un patch latent r√©el\n",
    "provenant d‚Äôune image d‚Äôentra√Ænement $x$.\n",
    "\n",
    "L‚Äôobjectif de cette √©tape est d‚Äôidentifier **quelle r√©gion de l‚Äôimage originale**\n",
    "(en espace pixel) correspond √† ce prototype afin de rendre le raisonnement du\n",
    "mod√®le visuellement interpr√©table.\n",
    "\n",
    "#### Principe g√©n√©ral\n",
    "\n",
    "Un prototype doit √™tre visualis√© √† partir de la r√©gion de l‚Äôimage\n",
    "qui **l‚Äôactive le plus fortement**.\n",
    "\n",
    "L‚Äôhypoth√®se est la suivante :\n",
    "> le patch de l‚Äôimage correspondant √† un prototype est celui\n",
    "> pour lequel l‚Äôactivation du prototype est maximale.\n",
    "\n",
    "#### Calcul de la carte d‚Äôactivation du prototype\n",
    "\n",
    "Pour une image d‚Äôentra√Ænement $x$ associ√©e au prototype $p_j$ :\n",
    "\n",
    "1. L‚Äôimage $x$ est propag√©e dans le r√©seau ProtoPNet entra√Æn√©\n",
    "2. Le prototype $p_j$ produit une **carte d‚Äôactivation spatiale**\n",
    "   via l‚Äôunit√© de prototype $g_{p_j}$\n",
    "3. Cette carte est extraite **avant l‚Äôop√©ration de max-pooling**\n",
    "\n",
    "#### Remise √† l‚Äô√©chelle spatiale (Upsampling)\n",
    "\n",
    "La carte d‚Äôactivation issue de $g_{p_j}$ est ensuite **redimensionn√©e**\n",
    "√† la taille de l‚Äôimage originale $x$.\n",
    "\n",
    "Cela permet d‚Äôassocier chaque activation latente\n",
    "√† une r√©gion pr√©cise de l‚Äôimage en espace pixel.\n",
    "\n",
    "$$\n",
    "A_j(x) = \\text{Upsample}\\left( g_{p_j}(f(x)) \\right)\n",
    "$$\n",
    "o√π :\n",
    "- $g_{p_j}$ d√©signe l‚Äôunit√© associ√©e au prototype $p_j$\n",
    "- $f(x)$ est la repr√©sentation latente de l‚Äôimage\n",
    "- $A_j(x)$ est la carte d‚Äôactivation du prototype $p_j$\n",
    "  √† la r√©solution de l‚Äôimage originale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dd1d42",
   "metadata": {},
   "source": [
    "#### S√©lection de la r√©gion la plus activ√©e\n",
    "\n",
    "La r√©gion visuelle associ√©e au prototype est d√©finie\n",
    "comme la **plus petite bo√Æte rectangulaire**\n",
    "contenant les pixels fortement activ√©s.\n",
    "\n",
    "$$\n",
    "\\mathcal{R}_j =\n",
    "\\left\\{\n",
    "u \\in x \\;\\middle|\\;\n",
    "A_j(x)[u] \\ge \\text{Percentile}_{95}(A_j(x))\n",
    "\\right\\}\n",
    "$$\n",
    "Le prototype $p_j$ est alors visualis√© √† l‚Äôaide du **plus petit rectangle**\n",
    "englobant tous les pixels de $ùì°_j$.\n",
    "\n",
    "Ce choix du **95·µâ percentile** permet :\n",
    "- d‚Äô√©liminer le bruit\n",
    "- de se concentrer sur la r√©gion la plus discriminante\n",
    "- d‚Äôobtenir une visualisation compacte et interpr√©table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3f879e",
   "metadata": {},
   "source": [
    "#### R√©sum√© de la visualisation des prototypes\n",
    "\n",
    "Pour chaque prototype :\n",
    "\n",
    "1. Propagation de l‚Äôimage associ√©e dans le r√©seau\n",
    "2. Extraction de la carte d‚Äôactivation du prototype\n",
    "3. Upsampling √† la taille de l‚Äôimage\n",
    "4. Seuil au 95·µâ percentile\n",
    "5. Extraction du patch visuel correspondant\n",
    "\n",
    "Cette proc√©dure permet de relier explicitement :\n",
    "- un **prototype latent**\n",
    "- un **concept visuel localis√©**\n",
    "- une **r√©gion interpr√©table de l‚Äôimage**\n",
    "\n",
    "Elle constitue un √©l√©ment central de l‚Äôexplicabilit√©\n",
    "de ProtoPNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95f1a2",
   "metadata": {},
   "source": [
    "## Exemple\n",
    "\n",
    "J'ai utilis√© un mod√®le entrain√© par une co-autrice de la m√©thode PPNet.\n",
    "Vous pouvez trouver le mod√®le [ici](https://drive.google.com/drive/folders/1C6gpcmIBu_djO5cUXPgjXi1FqIWa3eI6?usp=sharing) il est car absent sur ce d√©pot github.\n",
    "\n",
    "Pour plus d'infos comme comment entrainer votre propre mod√®le ou comment modifier l'architecture etc..., r√©ferez-vous [ici](./ProtoPNet_README.txt).\n",
    "\n",
    "Pour faire de la prediction, nous renseignons quelques informations dans le fichier analyse.ps1, √† savoir:\n",
    "- `-modeldir` : **dossier dans lequel le mod√®le d'annalyse est plac√©**\n",
    "- `-model` : **nom du modele**\n",
    "- `-imgdir` **dossier dans lequel l'image √† annalyser est plac√©**\n",
    "- `-img` : **nom de l'image**\n",
    "- `-imgclass` : **L'indice de la classe de l'image, sachant les indices commencent par 0**.\n",
    "\n",
    "voil√† un appercu:\n",
    "```ps1\n",
    "python local_analysis.py `\n",
    "-modeldir ./saved_models/1215_vgg16_retrain `\n",
    "-model 20_9push0.7337.pth `\n",
    "-imgdir ./images_test `\n",
    "-img European_Goldfinch_0006_794661.jpg `\n",
    "-imgclass 47\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83bdcf8",
   "metadata": {},
   "source": [
    "Voici l'image √† tester<br>\n",
    "![European_Goldfinch_0006_794661.jpg](images_test\\European_Goldfinch_0006_794661.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62925352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7113ba04",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
